# Foundations_of_RL

## [Multi-armed Bandits](https://github.com/atharva7am/Foundations_of_RL/tree/main/multiarm_bandits)
In this, I implemented and compared different algorithms for sampling the arms of a stochastic multi-armed bandit. The implemented algorithms are epsilon-greedy exploration, UCB, KL-UCB, Thompson Sampling, and a variation of the Thompson Sampling for tasks 3 and 4.<br>

Refer to this [report](https://github.com/atharva7am/Foundations_of_RL/blob/main/multiarm_bandits/submission/report.pdf) for more details of implementationa and results<br>

## [Anti-Tic-Tac-Toe](https://github.com/atharva7am/Foundations_of_RL/tree/main/anti_tic_tac_toe)
In this, I implemented three different algorithms for computing the optimal value function V* and an optimal policy Ï€* for a given MDP. The implemented algorithms are Value Iteration, Howard Policy Iteration and Linear Programming<br>

Refer to this [report](https://github.com/atharva7am/Foundations_of_RL/blob/main/anti_tic_tac_toe/report.pdf) for more details of implementationa and results<br>

## [Mountain Car](https://github.com/atharva7am/Foundations_of_RL/tree/main/mountain_car)
In this, I implemented SARSA(0) algorithm for the reinforcement learning
problem of an agent which can learn to escape the valley. The algorithm is implemented
using weights, and the weights are updated with linear TD(0).<br>

Refer to this [report](https://github.com/atharva7am/Foundations_of_RL/blob/main/mountain_car/report.pdf) for more details of implementationa and results
